{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing\n",
    "\n",
    "We now know what shape we want our data to be in:\n",
    "- player ID (as in ```player_idlist.csv```)\n",
    "- player name (full name to avoid ambiguities)\n",
    "- position (GK/DEF/MID/FWD)\n",
    "- gameweek \n",
    "- actual FPL points scored during gameweek\n",
    "- player value (price)\n",
    "- minutes played\n",
    "- expected goals\n",
    "- expected assists\n",
    "- expected goals conceded\n",
    "- goals scored\n",
    "- assists\n",
    "- goals conceded\n",
    "- ict index\n",
    "- fixture difficulty\n",
    "\n",
    "**We want one big csv file PER SEASON.**\n",
    "\n",
    "...let's get to work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2022-23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in raw data\n",
    "merged_gws_22_23 = pd.read_csv('../data/raw/2022-23/gws/merged_gw.csv')\n",
    "\n",
    "# omit all data prior to gameweek 16 (as there was no expected goal data before that)\n",
    "merged_gws_22_23 = merged_gws_22_23[merged_gws_22_23['GW'] > 15]\n",
    "\n",
    "# pick out useful subset of data\n",
    "merged_gws_22_23 = merged_gws_22_23[\n",
    "    [\n",
    "        'element',      # player ID\n",
    "        'name',\n",
    "        'position',\n",
    "        'GW',\n",
    "        'total_points',\n",
    "        'value',\n",
    "        'minutes',\n",
    "        'expected_goals',\n",
    "        'expected_assists',\n",
    "        'expected_goals_conceded',\n",
    "        'goals_scored',\n",
    "        'assists',\n",
    "        'goals_conceded',\n",
    "        'ict_index',\n",
    "        'fixture',\n",
    "        'was_home'      # we will use 'fixture' and 'was_home' to retrieve fixture difficulty\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we write code to extract fixture difficulty based on the columns 'fixture' and 'was_home'\n",
    "fixtures_22_23 = pd.read_csv('../data/raw/2022-23/fixtures.csv')\n",
    "fixtures_dict_22_23 = fixtures_22_23[['id', 'team_h_difficulty', 'team_a_difficulty']].set_index('id').T.to_dict()\n",
    "\n",
    "def add_fixture_difficulty(row, fixtures_dict):\n",
    "    fixture_id = row['fixture']\n",
    "    if row['was_home']:\n",
    "        team = 'team_h_difficulty'\n",
    "    else:\n",
    "        team = 'team_a_difficulty'\n",
    "    row['fixture_difficulty'] = fixtures_dict[fixture_id][team]\n",
    "\n",
    "    return row\n",
    "\n",
    "merged_gws_22_23 = merged_gws_22_23.apply(lambda row: add_fixture_difficulty(row=row, fixtures_dict=fixtures_dict_22_23), axis=1)\n",
    "\n",
    "# save processed data\n",
    "merged_gws_22_23.to_csv('../data/processed/2022-23/processed_merged_gws.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2023-24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in raw data\n",
    "merged_gws_23_24 = pd.read_csv('../data/raw/2023-24/gws/merged_gw.csv')\n",
    "\n",
    "# pick out useful subset of data\n",
    "merged_gws_23_24 = merged_gws_23_24[\n",
    "    [\n",
    "        'element',      # player ID\n",
    "        'name',\n",
    "        'position',\n",
    "        'GW',\n",
    "        'total_points',\n",
    "        'value',\n",
    "        'minutes',\n",
    "        'expected_goals',\n",
    "        'expected_assists',\n",
    "        'expected_goals_conceded',\n",
    "        'goals_scored',\n",
    "        'assists',\n",
    "        'goals_conceded',\n",
    "        'ict_index',\n",
    "        'fixture',\n",
    "        'was_home'      # we will use 'fixture' and 'was_home' to retrieve fixture difficulty\n",
    "    ]\n",
    "]\n",
    "\n",
    "# here we write code to extract fixture difficulty based on the columns 'fixture' and 'was_home'\n",
    "fixtures_23_24 = pd.read_csv('../data/raw/2023-24/fixtures.csv')\n",
    "fixtures_dict_23_24 = fixtures_23_24[['id', 'team_h_difficulty', 'team_a_difficulty']].set_index('id').T.to_dict()\n",
    "\n",
    "merged_gws_23_24 = merged_gws_23_24.apply(lambda row: add_fixture_difficulty(row=row, fixtures_dict=fixtures_dict_23_24), axis=1)\n",
    "\n",
    "# save processed data\n",
    "merged_gws_23_24.to_csv('../data/processed/2023-24/processed_merged_gws.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xfpl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

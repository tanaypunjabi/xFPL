{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "\n",
    "As mentioned in the end of the last notebook, we want to enrich our dataset (which currently consists only of single-gameweek data) by adding time-based cumulative features which can provide greater insight regarding player form.\n",
    "\n",
    "Before we begin, let's look at the features we currently have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['element', 'name', 'position', 'GW', 'total_points', 'value', 'minutes',\n",
       "       'expected_goals', 'expected_assists', 'expected_goals_conceded',\n",
       "       'goals_scored', 'assists', 'goals_conceded', 'clean_sheets',\n",
       "       'ict_index', 'fixture', 'was_home', 'fixture_difficulty'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# current features\n",
    "processed_24_25 = pd.read_csv('../data/processed/2024-25/processed_merged_gws.csv')\n",
    "current_features = processed_24_25.columns\n",
    "\n",
    "current_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's identify the features that we can potentially engineer and enhance:\n",
    "- **total_points**: this is the player's individual gameweek score. We can enhance this feature by taking the player's total or average gameweek score over the past few weeks.\n",
    "- We can do the same for **minutes played**, **goals and assists**, **expected goals and assists**, **goals conceded**, **expected goals conceded**, and **clean sheets**.\n",
    "\n",
    "We will choose a sliding time windows of **1 gameweek** and **3 gameweeks** as an initial attempt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features to be added\n",
    "\n",
    "- **avg_score_last_x**: Average gameweek score over the last (1,3) gameweeks.\n",
    "\n",
    "- **avg_mins_last_x**: Average minutes played over the last (1,3) gameweeks.\n",
    "\n",
    "- **goals_last_x**: Total goals scored over the last (1,3) gameweeks.\n",
    "\n",
    "- **assists_last_x**: Total assists over the last (1,3) gameweeks.\n",
    "\n",
    "- **xG_last_x**: Total expected goals over the last (1,3) gameweeks.\n",
    "\n",
    "- **xA_last_x**: Total expected assists over the last (1,3) gameweeks.\n",
    "\n",
    "- **ict_last_x**: Total ICT index over the last (1,3) gameweeks.\n",
    "\n",
    "- **goals_conceded_last_x**: Total goals conceded over the last (1,3) gameweeks.\n",
    "\n",
    "- **avg_xGC_last_x**: Average expected goals conceded over the last (1,3) gameweeks.\n",
    "\n",
    "- **clean_sheets_last_x**: Total clean sheets over the last (1,3) gameweeks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to calculate rolling features\n",
    "def calculate_rolling_features(df, window, min_p):\n",
    "    grouped = df.groupby('element')\n",
    "\n",
    "    # roll statistics\n",
    "    df[f'avg_score_last_{window}'] = (\n",
    "        grouped['total_points'].apply(\n",
    "            lambda x: x.shift(1).rolling(window, min_periods=min_p).mean()\n",
    "        ).reset_index(level=0, drop=True)\n",
    "    )\n",
    "\n",
    "    df[f'avg_mins_last_{window}'] = (\n",
    "        grouped['minutes'].apply(\n",
    "            lambda x: x.shift(1).rolling(window, min_periods=min_p).mean()\n",
    "        ).reset_index(level=0, drop=True)\n",
    "    )\n",
    "\n",
    "    df[f'goals_last_{window}'] = (\n",
    "        grouped['goals_scored'].apply(\n",
    "            lambda x: x.shift(1).rolling(window, min_periods=min_p).sum()\n",
    "        ).reset_index(level=0, drop=True)\n",
    "    )\n",
    "\n",
    "    df[f'assists_last_{window}'] = (\n",
    "        grouped['assists'].apply(\n",
    "            lambda x: x.shift(1).rolling(window, min_periods=min_p).sum()\n",
    "        ).reset_index(level=0, drop=True)\n",
    "    )\n",
    "\n",
    "    df[f'xG_last_{window}'] = (\n",
    "        grouped['expected_goals'].apply(\n",
    "            lambda x: x.shift(1).rolling(window, min_periods=min_p).sum()\n",
    "        ).reset_index(level=0, drop=True)\n",
    "    )\n",
    "\n",
    "    df[f'xA_last_{window}'] = (\n",
    "        grouped['expected_assists'].apply(\n",
    "            lambda x: x.shift(1).rolling(window, min_periods=min_p).sum()\n",
    "        ).reset_index(level=0, drop=True)\n",
    "    )\n",
    "\n",
    "    df[f'ict_last_{window}'] = (\n",
    "        grouped['ict_index'].apply(\n",
    "            lambda x: x.shift(1).rolling(window, min_periods=min_p).sum()\n",
    "        ).reset_index(level=0, drop=True)\n",
    "    )\n",
    "\n",
    "    df[f'goals_conceded_last_{window}'] = (\n",
    "        grouped['goals_conceded'].apply(\n",
    "            lambda x: x.shift(1).rolling(window, min_periods=min_p).sum()\n",
    "        ).reset_index(level=0, drop=True)\n",
    "    )\n",
    "\n",
    "    df[f'avg_xGC_last_{window}'] = (\n",
    "        grouped['expected_goals_conceded'].apply(\n",
    "            lambda x: x.shift(1).rolling(window, min_periods=min_p).mean()\n",
    "        ).reset_index(level=0, drop=True)\n",
    "    )\n",
    "\n",
    "    df[f'clean_sheets_last_{window}'] = (\n",
    "        grouped['clean_sheets'].apply(\n",
    "            lambda x: x.shift(1).rolling(window, min_periods=min_p).sum()\n",
    "        ).reset_index(level=0, drop=True)\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general function to faciliate feature engineering process\n",
    "def feature_engineering(df):\n",
    "    # sort by player and GW to ensure proper rolling calculations\n",
    "    df = df.sort_values(by=['element', 'GW'])\n",
    "\n",
    "    # main rolling calculations\n",
    "    fe_df = calculate_rolling_features(df, window=3, min_p=2)\n",
    "    fe_df = calculate_rolling_features(df, window=1, min_p=1)\n",
    "\n",
    "    # drop invalid rows (with NaN values)\n",
    "    fe_df = fe_df.dropna()\n",
    "    \n",
    "    return fe_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, time to put everything together and enhance our data\n",
    "### 2022-23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in processed data \n",
    "processed_merged_gws_22_23 = pd.read_csv('../data/processed/2022-23/processed_merged_gws.csv')\n",
    "\n",
    "# transform\n",
    "feature_engineered_22_23 = feature_engineering(processed_merged_gws_22_23)\n",
    "\n",
    "# output\n",
    "feature_engineered_22_23.to_csv('../data/processed/2022-23/feature_engineered_22_23.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2023-24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in processed data \n",
    "processed_merged_gws_23_24 = pd.read_csv('../data/processed/2023-24/processed_merged_gws.csv')\n",
    "\n",
    "# transform\n",
    "feature_engineered_23_24 = feature_engineering(processed_merged_gws_23_24)\n",
    "\n",
    "# output\n",
    "feature_engineered_23_24.to_csv('../data/processed/2023-24/feature_engineered_23_24.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2024-25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in processed data \n",
    "processed_merged_gws_24_25 = pd.read_csv('../data/processed/2024-25/processed_merged_gws.csv')\n",
    "\n",
    "# transform\n",
    "feature_engineered_24_25 = feature_engineering(processed_merged_gws_24_25)\n",
    "\n",
    "# output\n",
    "feature_engineered_24_25.to_csv('../data/processed/2024-25/feature_engineered_24_25.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xfpl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
